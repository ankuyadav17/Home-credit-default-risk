{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0L_NWJn5jUN",
        "colab_type": "code",
        "outputId": "b4655be9-7102-4381-a8e5-b2509433761b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3\" --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/9120/860599/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1581611378&Signature=XRXJdQkSswHY5iMTnjVSXiaJaaVY7zrXqaOliII2EaggoXI3pDpfrY5DyIJhiYaob1s1ZE6PVCR0H3%2BzSfb6ryuWmEO2n9fqsAGN7wRxGn6u7xW8Y7YC258RVjvTVKLvp2Ls5ODf4XexGqMTqteAhZ9nZIOPIeUTCiqN3sqAPr65JRgghDoYBx4eAnvXqMi7vVUx%2B5wMk86qQV1Qv64H4%2BVBpn3%2BZ2BDJOxcrc%2FK2W7lxs6VuSppzjbMH9MSJ9pqZMF2mI%2FfuBqDwf1ZwcaawK2GG7Gt20XZrCyuaVctcRT2GGShvIWpbjtj4q4G9Txo6Ry2o2N4YTosVuuP1pdROA%3D%3D&response-content-disposition=attachment%3B+filename%3Dhome-credit-default-risk.zip\" -O \"home-credit-default-risk.zip\" -c"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-10 16:29:58--  https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/9120/860599/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1581611378&Signature=XRXJdQkSswHY5iMTnjVSXiaJaaVY7zrXqaOliII2EaggoXI3pDpfrY5DyIJhiYaob1s1ZE6PVCR0H3%2BzSfb6ryuWmEO2n9fqsAGN7wRxGn6u7xW8Y7YC258RVjvTVKLvp2Ls5ODf4XexGqMTqteAhZ9nZIOPIeUTCiqN3sqAPr65JRgghDoYBx4eAnvXqMi7vVUx%2B5wMk86qQV1Qv64H4%2BVBpn3%2BZ2BDJOxcrc%2FK2W7lxs6VuSppzjbMH9MSJ9pqZMF2mI%2FfuBqDwf1ZwcaawK2GG7Gt20XZrCyuaVctcRT2GGShvIWpbjtj4q4G9Txo6Ry2o2N4YTosVuuP1pdROA%3D%3D&response-content-disposition=attachment%3B+filename%3Dhome-credit-default-risk.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.203.128, 2607:f8b0:400c:c04::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.203.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 721616255 (688M) [application/zip]\n",
            "Saving to: ‘home-credit-default-risk.zip’\n",
            "\n",
            "home-credit-default 100%[===================>] 688.19M   143MB/s    in 5.0s    \n",
            "\n",
            "2020-02-10 16:30:03 (138 MB/s) - ‘home-credit-default-risk.zip’ saved [721616255/721616255]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLyzdQLs5i2r",
        "colab_type": "code",
        "outputId": "fd4a2796-05ba-4e7a-f3bc-4f6f8d861f0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "!unzip 'home-credit-default-risk.zip'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  home-credit-default-risk.zip\n",
            "  inflating: HomeCredit_columns_description.csv  \n",
            "  inflating: POS_CASH_balance.csv    \n",
            "  inflating: application_test.csv    \n",
            "  inflating: application_train.csv   \n",
            "  inflating: bureau.csv              \n",
            "  inflating: bureau_balance.csv      \n",
            "  inflating: credit_card_balance.csv  \n",
            "  inflating: installments_payments.csv  \n",
            "  inflating: previous_application.csv  \n",
            "  inflating: sample_submission.csv   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p6bDSdM1rjzm",
        "outputId": "ea58f103-d01f-407c-9fda-e73523d1ea31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "!pip install lightgbm"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (2.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.22.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.17.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->lightgbm) (0.14.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SjD5GllE8luj",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AyQHVnbKrjWk",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "import pickle\n",
        "import numpy as np\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import roc_auc_score, roc_curve,auc\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "def final_fun_1(t_df):\n",
        "  # code taken from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
        "  def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    #print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    #print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    #print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "\n",
        "  \n",
        "  \n",
        "  def one_hot(df):\n",
        "    original_col = list(df.columns)\n",
        "    c = [c for c in df.columns if df[c].dtype == 'object']\n",
        "    df = pd.get_dummies(df, columns= c, dummy_na= True)\n",
        "    new_col = [c for c in df.columns if c not in original_col]\n",
        "    return df, new_col\n",
        " \n",
        "  df = reduce_mem_usage(pd.read_csv('application_train.csv'))\n",
        "  test_df = reduce_mem_usage(t_df)\n",
        "  df = df.append(test_df).reset_index()\n",
        "\n",
        "  df = df[df['CODE_GENDER'] != 'XNA']\n",
        "  df = df[df['AMT_GOODS_PRICE'].notnull()]\n",
        "  df = df[df['NAME_INCOME_TYPE'] != 'Maternity leave']\n",
        "  df = df[df['DAYS_LAST_PHONE_CHANGE'].notnull()]\n",
        "  df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
        "\n",
        "  df['DAYS_BIRTH / DAYS_EMPLOYED'] = df['DAYS_BIRTH'] / df['DAYS_EMPLOYED']\n",
        "\n",
        "  df['AMT_CREDIT / AMT_INCOME_TOTAL'] = df['AMT_CREDIT'] / df['AMT_INCOME_TOTAL']\n",
        "  df['CNT_FAM_MEMBERS / AMT_INCOME_TOTAL'] = df['CNT_FAM_MEMBERS'] / df['AMT_INCOME_TOTAL']\n",
        "  df['AMT_ANNUITY / AMT_INCOME_TOTAL'] = df['AMT_ANNUITY'] / (1 + df['AMT_INCOME_TOTAL'])\n",
        "    \n",
        "  df['AMT_CREDIT / AMT_ANNUITY'] = df['AMT_CREDIT'] / df['AMT_ANNUITY']\n",
        "  df['ANNUITY_LENGTH / DAYS_EMPLOYED'] = df['AMT_CREDIT / AMT_ANNUITY'] / df['DAYS_EMPLOYED']\n",
        "  df['CNT_CHILDREN / CNT_FAM_MEMBERS'] = df['CNT_CHILDREN'] / df['CNT_FAM_MEMBERS']\n",
        "  \n",
        "  df['AMT_CREDIT / AMT_GOODS_PRICE'] = df['AMT_CREDIT'] / df['AMT_GOODS_PRICE']\n",
        "  df['AMT_CREDIT / AMT_GOODS_PRICE'] = df['AMT_CREDIT'] - df['AMT_GOODS_PRICE']\n",
        "  df['DAYS_REGISTRATION / DAYS_ID_PUBLISH'] = df['DAYS_REGISTRATION'] / df['DAYS_ID_PUBLISH']\n",
        "  df['DAYS_BIRTH / DAYS_REGISTRATION'] = df['DAYS_BIRTH'] / df['DAYS_REGISTRATION']\n",
        "  df['DOC_SUM'] = df['FLAG_DOCUMENT_2'] + df['FLAG_DOCUMENT_3'] + df['FLAG_DOCUMENT_4'] + df['FLAG_DOCUMENT_5'] + df['FLAG_DOCUMENT_6'] + df['FLAG_DOCUMENT_7'] + df['FLAG_DOCUMENT_8'] + df['FLAG_DOCUMENT_9'] + df['FLAG_DOCUMENT_10'] +df['FLAG_DOCUMENT_11'] + df['FLAG_DOCUMENT_12'] + df['FLAG_DOCUMENT_13'] + df['FLAG_DOCUMENT_14'] + df['FLAG_DOCUMENT_15'] + df['FLAG_DOCUMENT_16'] + df['FLAG_DOCUMENT_17'] + df['FLAG_DOCUMENT_18'] + df['FLAG_DOCUMENT_19'] + df['FLAG_DOCUMENT_20'] + df['FLAG_DOCUMENT_21']\n",
        "\n",
        "  df['NAN_AMT_ANNUITY'] = 1.0*np.isnan(df['AMT_ANNUITY'])\n",
        "  df['AGE_FINISH'] = df['DAYS_BIRTH']*(-1.0/365) + (df['AMT_CREDIT']/df['AMT_ANNUITY']) *(1.0/12) #how old when finish\n",
        "    \n",
        "  docs = [data for data in df.columns if 'FLAG_DOC' in data]\n",
        "  live = [data for data in df.columns if ('FLAG_' in data) & ('FLAG_DOC' not in data) & ('_FLAG_' not in data)]\n",
        "  df['NEW_DOC_IND_KURT'] = df[docs].kurtosis(axis=1)\n",
        "  df['NEW_LIVE_IND_SUM'] = df[live].sum(axis=1)\n",
        "  df['AMT_INCOME_TOTAL / CNT_CHILDREN'] = df['AMT_INCOME_TOTAL'] / (1 + df['CNT_CHILDREN'])\n",
        "  org_type = df[['AMT_INCOME_TOTAL', 'ORGANIZATION_TYPE']].groupby('ORGANIZATION_TYPE').median()['AMT_INCOME_TOTAL']\n",
        "  df['NEW_INC_BY_ORG'] = df['ORGANIZATION_TYPE'].map(org_type)\n",
        "  df['AMT_INCOME_TOTAL / NEW_INC_BY_ORG'] = df['AMT_INCOME_TOTAL'] / df['NEW_INC_BY_ORG']\n",
        "  df['OWN_CAR_AGE / DAYS_BIRTH'] = df['OWN_CAR_AGE'] / df['DAYS_BIRTH']\n",
        "  df['OWN_CAR_AGE / DAYS_EMPLOYED'] = df['OWN_CAR_AGE'] / df['DAYS_EMPLOYED']\n",
        "  df['DAYS_LAST_PHONE_CHANGE / DAYS_BIRTH'] = df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_BIRTH']\n",
        "  df['DAYS_LAST_PHONE_CHANGE / DAYS_EMPLOYED'] = df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_EMPLOYED']\n",
        "     \n",
        "  for f in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
        "      df[f], c = pd.factorize(df[f])\n",
        "\n",
        "  cat_col = [i for i in df.columns if df[i].dtype == 'object']\n",
        "  df = pd.get_dummies(df, columns= cat_col)\n",
        "\n",
        "  df= df.drop(['FLAG_DOCUMENT_2','FLAG_DOCUMENT_4','FLAG_DOCUMENT_5','FLAG_DOCUMENT_6','FLAG_DOCUMENT_7',\n",
        "    'FLAG_DOCUMENT_8','FLAG_DOCUMENT_9','FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11','FLAG_DOCUMENT_12','FLAG_DOCUMENT_13',\n",
        "    'FLAG_DOCUMENT_14','FLAG_DOCUMENT_15','FLAG_DOCUMENT_16','FLAG_DOCUMENT_17','FLAG_DOCUMENT_18','FLAG_DOCUMENT_19',\n",
        "    'FLAG_DOCUMENT_20','FLAG_DOCUMENT_21'],axis=1)\n",
        "  #print(df.shape) \n",
        "  del t_df,test_df\n",
        "  gc.collect()\n",
        "\n",
        "  def b_new(buro):\n",
        "    bureau_balance = reduce_mem_usage(pd.read_csv('bureau_balance.csv'))\n",
        "    bureau_balance, col1 = one_hot(bureau_balance)\n",
        "    bureau, col2= one_hot(buro)\n",
        "\n",
        "    bureau_balance_agg = {'MONTHS_BALANCE': ['size']}\n",
        "    for c in col1:\n",
        "      bureau_balance_agg[c] = ['mean']\n",
        "    aggregate = bureau_balance.groupby('SK_ID_BUREAU').agg(bureau_balance_agg)\n",
        "    l=[]\n",
        "    for i in aggregate.columns.tolist():\n",
        "      l.append(i[0] + \"_\" + i[1].upper())\n",
        "    \n",
        "    aggregate.columns = pd.Index(l)\n",
        "    bureau = bureau.join(aggregate, how='left', on='SK_ID_BUREAU')\n",
        "    bureau.drop(['SK_ID_BUREAU'], axis=1, inplace= True)\n",
        "    del aggregate\n",
        "    gc.collect()\n",
        "    \n",
        "    numerical_agg = {'AMT_CREDIT_SUM_DEBT': ['mean', 'sum'],'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
        "        'DAYS_CREDIT': ['mean', 'var'],'DAYS_CREDIT_UPDATE': ['mean'],'CREDIT_DAY_OVERDUE': ['mean'],\n",
        "        'DAYS_CREDIT_ENDDATE': ['mean'],'CNT_CREDIT_PROLONG': ['sum'],'MONTHS_BALANCE_SIZE': ['mean', 'sum'],\n",
        "        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
        "        'AMT_ANNUITY': ['max', 'mean'],'AMT_CREDIT_SUM': ['mean', 'sum']\n",
        "      }\n",
        "    categorical_agg = {}\n",
        "    for c in col2:\n",
        "      categorical_agg[c] = ['mean']\n",
        "    for c in col1:\n",
        "      categorical_agg[c + \"_MEAN\"] = ['mean']\n",
        "    \n",
        "    b1 = bureau.groupby('SK_ID_CURR').agg({**numerical_agg, **categorical_agg})\n",
        "    l=[]\n",
        "    for i in b1.columns.tolist():\n",
        "      l.append('BU_'+i[0]+'_'+i[1].upper())\n",
        "    b1.columns = pd.Index(l)\n",
        "     \n",
        "    A = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
        "    A_agg = A.groupby('SK_ID_CURR').agg(numerical_agg)\n",
        "    l=[]\n",
        "    for i in A_agg.columns.tolist():\n",
        "      l.append('A_'+i[0]+'_'+i[1].upper())\n",
        "    A_agg.columns = pd.Index(l)\n",
        "    b1 = b1.join(A_agg, how='left', on='SK_ID_CURR')\n",
        "    del A,A_agg\n",
        "    gc.collect()\n",
        "\n",
        "    C = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
        "    C_agg = C.groupby('SK_ID_CURR').agg(numerical_agg)\n",
        "    l=[]\n",
        "    for i in C_agg.columns.tolist():\n",
        "      l.append('C_'+i[0]+'_'+i[1].upper())\n",
        "    C_agg.columns = pd.Index(l)\n",
        "    b1 = b1.join(C_agg, how='left', on='SK_ID_CURR')\n",
        "    del C, C_agg\n",
        "    gc.collect()\n",
        "  \n",
        "    #print(b1.shape)\n",
        "    del bureau\n",
        "    gc.collect()\n",
        "    return(b1)\n",
        "\n",
        " \n",
        "  def pos_cash(pos):\n",
        "    pos_ch, col = one_hot(pos)\n",
        "    aggregate = {'SK_DPD_DEF': ['max', 'mean'],'SK_DPD': ['max', 'mean'],\n",
        "        'MONTHS_BALANCE': ['max', 'mean', 'size']\n",
        "        \n",
        "    }\n",
        "    for c in col:\n",
        "        aggregate[c] = ['mean']\n",
        "    \n",
        "    A_agg = pos_ch.groupby('SK_ID_CURR').agg(aggregate)\n",
        "    l=[]\n",
        "    for i in A_agg.columns.tolist():\n",
        "      l.append('POS_'+i[0] + '_' + i[1].upper())\n",
        "    A_agg.columns = pd.Index(l)\n",
        "    A_agg['POS_no_COUNT'] = pos_ch.groupby('SK_ID_CURR').size()\n",
        "\n",
        "    value=pos_ch.groupby('SK_ID_CURR')['MONTHS_BALANCE'].min()\n",
        "    A_agg['MIN_VALUES']=pos_ch['SK_ID_CURR'].map(value)\n",
        "    A_agg['MULTIPLIER']=1.00-pos_ch['MONTHS_BALANCE']/A_agg['MIN_VALUES']\n",
        "    #print(A_agg.shape)\n",
        "    del pos_ch\n",
        "    gc.collect()\n",
        "    return A_agg\n",
        "\n",
        "  def credit_card(cre):\n",
        "    credit_card, col = one_hot(cre)\n",
        "    credit_card.drop(['SK_ID_PREV'], axis= 1, inplace = True)\n",
        "    credit_card_agg = credit_card.groupby('SK_ID_CURR').agg(['max', 'mean', 'sum', 'var'])\n",
        "    l=[]\n",
        "    for i in credit_card_agg.columns.tolist():\n",
        "      l.append('CR_'+i[0]+'_'+i[1].upper())\n",
        "    credit_card_agg.columns = pd.Index(l)\n",
        "    # Count credit card lines\n",
        "    credit_card_agg['CR_no_COUNT'] = credit_card.groupby('SK_ID_CURR').size()\n",
        "    #print(credit_card_agg.shape)\n",
        "    del credit_card\n",
        "    gc.collect()\n",
        "    return credit_card_agg\n",
        "\n",
        "  def previous_app(prev):\n",
        "    p_app, p_app_cols = one_hot(prev)\n",
        "    p_app['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
        "    p_app['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
        "    p_app['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
        "    p_app['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
        "    p_app['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
        "    p_app['APP_CREDIT_PERC'] = p_app['AMT_APPLICATION'] / p_app['AMT_CREDIT']\n",
        "    num_agg = {'AMT_DOWN_PAYMENT': ['max', 'mean'],'DAYS_DECISION': ['max', 'mean'],\n",
        "                        'AMT_GOODS_PRICE': ['max', 'mean'],'AMT_ANNUITY': ['max', 'mean'],'HOUR_APPR_PROCESS_START': ['max', 'mean'],\n",
        "        'RATE_DOWN_PAYMENT': ['max', 'mean'],'AMT_APPLICATION': ['max', 'mean'],\n",
        "        'AMT_CREDIT': ['max', 'mean'],'APP_CREDIT_PERC': ['max', 'mean'],'CNT_PAYMENT': ['mean', 'sum'] \n",
        "          \n",
        "    }\n",
        "    cat_agg = {}\n",
        "    for cat in p_app_cols:\n",
        "        cat_agg[cat] = ['mean']\n",
        "    \n",
        "    P1 = p_app.groupby('SK_ID_CURR').agg({**num_agg, **cat_agg})\n",
        "    l=[]\n",
        "    for i in P1.columns.tolist():\n",
        "      l.append('PR_'+i[0]+'_'+i[1].upper())\n",
        "    P1.columns = pd.Index(l)\n",
        "    A = p_app[p_app['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
        "    A_agg = A.groupby('SK_ID_CURR').agg(num_agg)\n",
        "    l=[]\n",
        "    for i in A_agg.columns.tolist():\n",
        "      l.append('APP_'+i[0]+'_'+i[1].upper())\n",
        "    A_agg.columns = pd.Index(l)\n",
        "    P1 = P1.join(A_agg, how='left', on='SK_ID_CURR')\n",
        "    R = p_app[p_app['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
        "    R_agg = R.groupby('SK_ID_CURR').agg(num_agg)\n",
        "    l=[]\n",
        "    for i in R_agg.columns.tolist():\n",
        "      l.append('REF_'+i[0]+'_'+i[1].upper())\n",
        "    \n",
        "    R_agg.columns = pd.Index(l)\n",
        "    P1 = P1.join(R_agg, how='left', on='SK_ID_CURR')\n",
        "    del R, R_agg, A, A_agg, p_app\n",
        "    gc.collect()\n",
        "    #print(P1.shape)\n",
        "    return P1\n",
        "\n",
        "  def inst_pay(ins):\n",
        "    A, col = one_hot(ins)\n",
        "    \n",
        "    aggregate = {'days_late_on_payment': ['max','mean','min','sum'],'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
        "        'NUM_INSTALMENT_VERSION': ['nunique'],'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
        "        'amount_extra_paid': ['max','mean','min','sum'],'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']     \n",
        "    }\n",
        "    for c in col:\n",
        "        aggregate[c] = ['mean']\n",
        "    A_agg = A.groupby('SK_ID_CURR').agg(aggregate)\n",
        "    l=[]\n",
        "    for i in A_agg.columns.tolist():\n",
        "      l.append('INS_'+i[0]+'_'+i[1].upper())\n",
        "    A_agg.columns = pd.Index(l)\n",
        "    A_agg['INSTAL_no_COUNT'] = A.groupby('SK_ID_CURR').size()\n",
        "    del A\n",
        "    gc.collect()\n",
        "    #print(A_agg.shape)\n",
        "    return A_agg\n",
        "\n",
        "\n",
        "  b=pd.read_csv('bureau.csv')\n",
        "     \n",
        "  new = b_new(reduce_mem_usage(b))\n",
        "  df = df.join(new, how='left', on='SK_ID_CURR')\n",
        "  del new\n",
        "  gc.collect()\n",
        "\n",
        "    \n",
        "  pr = pd.read_csv('previous_application.csv')\n",
        "\n",
        "  frame = previous_app(reduce_mem_usage(pr))\n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(pr[pr.DAYS_DECISION  >=-365].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = previous_app(frame)\n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_year')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "  \n",
        "  frame = reduce_mem_usage(pr[pr.DAYS_DECISION  >=-182].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = previous_app(frame)      \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_halfyear')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(pr[pr.DAYS_DECISION  >=-92].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = previous_app(frame)      \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_quarter')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(pr[pr.DAYS_DECISION  >=-31].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = previous_app(frame)      \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_month')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(pr[pr.DAYS_DECISION  >=-8].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = previous_app(frame)      \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_week')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  c = reduce_mem_usage(pd.read_csv('POS_CASH_balance.csv'))\n",
        "  frame = pos_cash(c)\n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "        \n",
        "  frame = reduce_mem_usage(c[c.MONTHS_BALANCE >=-12].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = pos_cash(frame)\n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_year')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "  \n",
        "  frame = reduce_mem_usage(c[c.MONTHS_BALANCE >=-6].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = pos_cash(frame)\n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_halfyear')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(c[c.MONTHS_BALANCE >=-3].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = pos_cash(frame)      \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_quarter')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(c[c.MONTHS_BALANCE >=-1].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = pos_cash(frame)      \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_month')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "\n",
        "  #i=pd.read_csv('inst_feats.csv')\n",
        "  i=pd.read_csv('installments_payments.csv')\n",
        "  i['DAYS_ENTRY_PAYMENT'].fillna(100, inplace=True)\n",
        "  i['AMT_PAYMENT'].fillna(0.0, inplace=True)\n",
        "  i['days_late_on_payment']=i.DAYS_ENTRY_PAYMENT-i.DAYS_INSTALMENT\n",
        "  i['amount_extra_paid']=i.AMT_PAYMENT-i.AMT_INSTALMENT\n",
        "  i = reduce_mem_usage(i)\n",
        "  frame = inst_pay(i)\n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(i[i.DAYS_INSTALMENT  >=-365].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = inst_pay(frame)      \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_year')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(i[i.DAYS_INSTALMENT  >=-182].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = inst_pay(frame)       \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_halfyear')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(i[i.DAYS_INSTALMENT  >=-92].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = inst_pay(frame)       \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_quarter')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(i[i.DAYS_INSTALMENT  >=-31].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = inst_pay(frame)       \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_month')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(i[i.DAYS_INSTALMENT  >=-8].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = inst_pay(frame)       \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_week')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  cr=pd.read_csv('credit_card_balance.csv')\n",
        "  frame = credit_card(reduce_mem_usage(cr))\n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(cr[cr.MONTHS_BALANCE >=-12].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = credit_card(frame)     \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_year')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(cr[cr.MONTHS_BALANCE >=-6].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = credit_card(frame)      \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_halfyear')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(cr[cr.MONTHS_BALANCE >=-3].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = credit_card(frame)     \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_quarter')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(cr[cr.MONTHS_BALANCE >=-1].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = credit_card(frame)      \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_month')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  with open('98_model1.pickle', 'rb') as handle:\n",
        "    m1 = pickle.load(handle)\n",
        "  with open('98_model2.pickle', 'rb') as handle:\n",
        "    m2 = pickle.load(handle)\n",
        "  with open('98_model3.pickle', 'rb') as handle:\n",
        "    m3 = pickle.load(handle)\n",
        "  with open('98_model4.pickle', 'rb') as handle:\n",
        "    m4 = pickle.load(handle)\n",
        "  with open('98_model5.pickle', 'rb') as handle:\n",
        "    m5 = pickle.load(handle)\n",
        "  with open('98_model6.pickle', 'rb') as handle:\n",
        "    m6 = pickle.load(handle)\n",
        "  with open('98_model7.pickle', 'rb') as handle:\n",
        "    m7 = pickle.load(handle)\n",
        "  with open('98_model8.pickle', 'rb') as handle:\n",
        "    m8 = pickle.load(handle)\n",
        "  with open('98_model9.pickle', 'rb') as handle:\n",
        "    m9 = pickle.load(handle)\n",
        "  with open('98_model10.pickle', 'rb') as handle:\n",
        "    m10 = pickle.load(handle)  \n",
        "\n",
        "  train_df = df[df['TARGET'].notnull()]\n",
        "  test_df = df[df['TARGET'].isnull()]\n",
        "  #print(\"test shape: {}\".format(test_df.shape))\n",
        "  del df\n",
        "  gc.collect()\n",
        "\n",
        "  feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
        "  out = np.zeros(test_df.shape[0])\n",
        "  \n",
        "  out += m1.predict_proba(test_df[feats], num_iteration=m1.best_iteration_)[:, 1] / 10\n",
        "  #print('model1 finish')\n",
        "  out += m2.predict_proba(test_df[feats], num_iteration=m2.best_iteration_)[:, 1] / 10\n",
        "  #print('model2 finish')\n",
        "  out += m3.predict_proba(test_df[feats], num_iteration=m3.best_iteration_)[:, 1] / 10\n",
        "  #print('model3 finish')\n",
        "  out += m4.predict_proba(test_df[feats], num_iteration=m4.best_iteration_)[:, 1] / 10\n",
        "  #print('model4 finish')\n",
        "  out += m5.predict_proba(test_df[feats], num_iteration=m5.best_iteration_)[:, 1] / 10\n",
        "  #print('model5 finish')\n",
        "  out += m6.predict_proba(test_df[feats], num_iteration=m6.best_iteration_)[:, 1] / 10\n",
        "  #print('model6 finish')\n",
        "  out += m7.predict_proba(test_df[feats], num_iteration=m7.best_iteration_)[:, 1] / 10\n",
        "  #print('model7 finish')\n",
        "  out += m8.predict_proba(test_df[feats], num_iteration=m8.best_iteration_)[:, 1] / 10\n",
        "  #print('model8 finish')\n",
        "  out += m9.predict_proba(test_df[feats], num_iteration=m9.best_iteration_)[:, 1] / 10\n",
        "  #print('model9 finish')\n",
        "  out += m10.predict_proba(test_df[feats], num_iteration=m10.best_iteration_)[:, 1] / 10\n",
        "  #print('model10 finish')\n",
        "\n",
        "  test_df['TARGET'] = out\n",
        "  test_df[['SK_ID_CURR', 'TARGET']].to_csv('test1_model.csv', index= False)\n",
        "  return test_df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJk43_zlsKMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "import pickle\n",
        "import numpy as np\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import roc_auc_score, roc_curve,auc\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import pandas as pd\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "def final_fun_2(t_df,y):\n",
        "  # code taken from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
        "  def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    #print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    #print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    #print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "\n",
        "  \n",
        "  \n",
        "  def one_hot(df):\n",
        "    original_col = list(df.columns)\n",
        "    c = [c for c in df.columns if df[c].dtype == 'object']\n",
        "    df = pd.get_dummies(df, columns= c, dummy_na= True)\n",
        "    new_col = [c for c in df.columns if c not in original_col]\n",
        "    return df, new_col\n",
        " \n",
        "  #df = reduce_mem_usage(pd.read_csv('application_train.csv'))\n",
        "  df = reduce_mem_usage(t_df)\n",
        "  #df = df.reset_index()\n",
        " \n",
        "  df = df[df['CODE_GENDER'] != 'XNA']\n",
        "  df = df[df['AMT_GOODS_PRICE'].notnull()]\n",
        "  df = df[df['NAME_INCOME_TYPE'] != 'Maternity leave']\n",
        "  df = df[df['DAYS_LAST_PHONE_CHANGE'].notnull()]\n",
        "  df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
        "\n",
        "  df['DAYS_BIRTH / DAYS_EMPLOYED'] = df['DAYS_BIRTH'] / df['DAYS_EMPLOYED']\n",
        "\n",
        "  df['AMT_CREDIT / AMT_INCOME_TOTAL'] = df['AMT_CREDIT'] / df['AMT_INCOME_TOTAL']\n",
        "  df['CNT_FAM_MEMBERS / AMT_INCOME_TOTAL'] = df['CNT_FAM_MEMBERS'] / df['AMT_INCOME_TOTAL']\n",
        "  df['AMT_ANNUITY / AMT_INCOME_TOTAL'] = df['AMT_ANNUITY'] / (1 + df['AMT_INCOME_TOTAL'])\n",
        "    \n",
        "  df['AMT_CREDIT / AMT_ANNUITY'] = df['AMT_CREDIT'] / df['AMT_ANNUITY']\n",
        "  df['ANNUITY_LENGTH / DAYS_EMPLOYED'] = df['AMT_CREDIT / AMT_ANNUITY'] / df['DAYS_EMPLOYED']\n",
        "  df['CNT_CHILDREN / CNT_FAM_MEMBERS'] = df['CNT_CHILDREN'] / df['CNT_FAM_MEMBERS']\n",
        "  \n",
        "  df['AMT_CREDIT / AMT_GOODS_PRICE'] = df['AMT_CREDIT'] / df['AMT_GOODS_PRICE']\n",
        "  df['AMT_CREDIT / AMT_GOODS_PRICE'] = df['AMT_CREDIT'] - df['AMT_GOODS_PRICE']\n",
        "  df['DAYS_REGISTRATION / DAYS_ID_PUBLISH'] = df['DAYS_REGISTRATION'] / df['DAYS_ID_PUBLISH']\n",
        "  df['DAYS_BIRTH / DAYS_REGISTRATION'] = df['DAYS_BIRTH'] / df['DAYS_REGISTRATION']\n",
        "  df['DOC_SUM'] = df['FLAG_DOCUMENT_2'] + df['FLAG_DOCUMENT_3'] + df['FLAG_DOCUMENT_4'] + df['FLAG_DOCUMENT_5'] + df['FLAG_DOCUMENT_6'] + df['FLAG_DOCUMENT_7'] + df['FLAG_DOCUMENT_8'] + df['FLAG_DOCUMENT_9'] + df['FLAG_DOCUMENT_10'] +df['FLAG_DOCUMENT_11'] + df['FLAG_DOCUMENT_12'] + df['FLAG_DOCUMENT_13'] + df['FLAG_DOCUMENT_14'] + df['FLAG_DOCUMENT_15'] + df['FLAG_DOCUMENT_16'] + df['FLAG_DOCUMENT_17'] + df['FLAG_DOCUMENT_18'] + df['FLAG_DOCUMENT_19'] + df['FLAG_DOCUMENT_20'] + df['FLAG_DOCUMENT_21']\n",
        "\n",
        "  df['NAN_AMT_ANNUITY'] = 1.0*np.isnan(df['AMT_ANNUITY'])\n",
        "  df['AGE_FINISH'] = df['DAYS_BIRTH']*(-1.0/365) + (df['AMT_CREDIT']/df['AMT_ANNUITY']) *(1.0/12) #how old when finish\n",
        "    \n",
        "  docs = [data for data in df.columns if 'FLAG_DOC' in data]\n",
        "  live = [data for data in df.columns if ('FLAG_' in data) & ('FLAG_DOC' not in data) & ('_FLAG_' not in data)]\n",
        "  df['NEW_DOC_IND_KURT'] = df[docs].kurtosis(axis=1)\n",
        "  df['NEW_LIVE_IND_SUM'] = df[live].sum(axis=1)\n",
        "  df['AMT_INCOME_TOTAL / CNT_CHILDREN'] = df['AMT_INCOME_TOTAL'] / (1 + df['CNT_CHILDREN'])\n",
        "  org_type = df[['AMT_INCOME_TOTAL', 'ORGANIZATION_TYPE']].groupby('ORGANIZATION_TYPE').median()['AMT_INCOME_TOTAL']\n",
        "  df['NEW_INC_BY_ORG'] = df['ORGANIZATION_TYPE'].map(org_type)\n",
        "  df['AMT_INCOME_TOTAL / NEW_INC_BY_ORG'] = df['AMT_INCOME_TOTAL'] / df['NEW_INC_BY_ORG']\n",
        "  df['OWN_CAR_AGE / DAYS_BIRTH'] = df['OWN_CAR_AGE'] / df['DAYS_BIRTH']\n",
        "  df['OWN_CAR_AGE / DAYS_EMPLOYED'] = df['OWN_CAR_AGE'] / df['DAYS_EMPLOYED']\n",
        "  df['DAYS_LAST_PHONE_CHANGE / DAYS_BIRTH'] = df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_BIRTH']\n",
        "  df['DAYS_LAST_PHONE_CHANGE / DAYS_EMPLOYED'] = df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_EMPLOYED']\n",
        "     \n",
        "  for f in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
        "      df[f], c = pd.factorize(df[f])\n",
        "\n",
        "  cat_col = [i for i in df.columns if df[i].dtype == 'object']\n",
        "  df = pd.get_dummies(df, columns= cat_col)\n",
        "\n",
        "  df= df.drop(['FLAG_DOCUMENT_2','FLAG_DOCUMENT_4','FLAG_DOCUMENT_5','FLAG_DOCUMENT_6','FLAG_DOCUMENT_7',\n",
        "    'FLAG_DOCUMENT_8','FLAG_DOCUMENT_9','FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11','FLAG_DOCUMENT_12','FLAG_DOCUMENT_13',\n",
        "    'FLAG_DOCUMENT_14','FLAG_DOCUMENT_15','FLAG_DOCUMENT_16','FLAG_DOCUMENT_17','FLAG_DOCUMENT_18','FLAG_DOCUMENT_19',\n",
        "    'FLAG_DOCUMENT_20','FLAG_DOCUMENT_21'],axis=1)\n",
        "  #print(df.shape) \n",
        "  del t_df\n",
        "  gc.collect()\n",
        "\n",
        "  def b_new(buro):\n",
        "    bureau_balance = reduce_mem_usage(pd.read_csv('bureau_balance.csv'))\n",
        "    bureau_balance, col1 = one_hot(bureau_balance)\n",
        "    bureau, col2= one_hot(buro)\n",
        "\n",
        "    bureau_balance_agg = {'MONTHS_BALANCE': ['size']}\n",
        "    for c in col1:\n",
        "      bureau_balance_agg[c] = ['mean']\n",
        "    aggregate = bureau_balance.groupby('SK_ID_BUREAU').agg(bureau_balance_agg)\n",
        "    l=[]\n",
        "    for i in aggregate.columns.tolist():\n",
        "      l.append(i[0] + \"_\" + i[1].upper())\n",
        "    \n",
        "    aggregate.columns = pd.Index(l)\n",
        "    bureau = bureau.join(aggregate, how='left', on='SK_ID_BUREAU')\n",
        "    bureau.drop(['SK_ID_BUREAU'], axis=1, inplace= True)\n",
        "    del aggregate\n",
        "    gc.collect()\n",
        "    \n",
        "    numerical_agg = {'AMT_CREDIT_SUM_DEBT': ['mean', 'sum'],'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
        "        'DAYS_CREDIT': ['mean', 'var'],'DAYS_CREDIT_UPDATE': ['mean'],'CREDIT_DAY_OVERDUE': ['mean'],\n",
        "        'DAYS_CREDIT_ENDDATE': ['mean'],'CNT_CREDIT_PROLONG': ['sum'],'MONTHS_BALANCE_SIZE': ['mean', 'sum'],\n",
        "        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
        "        'AMT_ANNUITY': ['max', 'mean'],'AMT_CREDIT_SUM': ['mean', 'sum']\n",
        "      }\n",
        "    categorical_agg = {}\n",
        "    for c in col2:\n",
        "      categorical_agg[c] = ['mean']\n",
        "    for c in col1:\n",
        "      categorical_agg[c + \"_MEAN\"] = ['mean']\n",
        "    \n",
        "    b1 = bureau.groupby('SK_ID_CURR').agg({**numerical_agg, **categorical_agg})\n",
        "    l=[]\n",
        "    for i in b1.columns.tolist():\n",
        "      l.append('BU_'+i[0]+'_'+i[1].upper())\n",
        "    b1.columns = pd.Index(l)\n",
        "     \n",
        "    A = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
        "    A_agg = A.groupby('SK_ID_CURR').agg(numerical_agg)\n",
        "    l=[]\n",
        "    for i in A_agg.columns.tolist():\n",
        "      l.append('A_'+i[0]+'_'+i[1].upper())\n",
        "    A_agg.columns = pd.Index(l)\n",
        "    b1 = b1.join(A_agg, how='left', on='SK_ID_CURR')\n",
        "    del A,A_agg\n",
        "    gc.collect()\n",
        "\n",
        "    C = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
        "    C_agg = C.groupby('SK_ID_CURR').agg(numerical_agg)\n",
        "    l=[]\n",
        "    for i in C_agg.columns.tolist():\n",
        "      l.append('C_'+i[0]+'_'+i[1].upper())\n",
        "    C_agg.columns = pd.Index(l)\n",
        "    b1 = b1.join(C_agg, how='left', on='SK_ID_CURR')\n",
        "    del C, C_agg\n",
        "    gc.collect()\n",
        "  \n",
        "    #print(b1.shape)\n",
        "    del bureau\n",
        "    gc.collect()\n",
        "    return(b1)\n",
        "\n",
        " \n",
        "  def pos_cash(pos):\n",
        "    pos_ch, col = one_hot(pos)\n",
        "    aggregate = {'SK_DPD_DEF': ['max', 'mean'],'SK_DPD': ['max', 'mean'],\n",
        "        'MONTHS_BALANCE': ['max', 'mean', 'size']\n",
        "        \n",
        "    }\n",
        "    for c in col:\n",
        "        aggregate[c] = ['mean']\n",
        "    \n",
        "    A_agg = pos_ch.groupby('SK_ID_CURR').agg(aggregate)\n",
        "    l=[]\n",
        "    for i in A_agg.columns.tolist():\n",
        "      l.append('POS_'+i[0] + '_' + i[1].upper())\n",
        "    A_agg.columns = pd.Index(l)\n",
        "    A_agg['POS_no_COUNT'] = pos_ch.groupby('SK_ID_CURR').size()\n",
        "\n",
        "    value=pos_ch.groupby('SK_ID_CURR')['MONTHS_BALANCE'].min()\n",
        "    A_agg['MIN_VALUES']=pos_ch['SK_ID_CURR'].map(value)\n",
        "    A_agg['MULTIPLIER']=1.00-pos_ch['MONTHS_BALANCE']/A_agg['MIN_VALUES']\n",
        "    #print(A_agg.shape)\n",
        "    del pos_ch\n",
        "    gc.collect()\n",
        "    return A_agg\n",
        "\n",
        "  def credit_card(cre):\n",
        "    credit_card, col = one_hot(cre)\n",
        "    credit_card.drop(['SK_ID_PREV'], axis= 1, inplace = True)\n",
        "    credit_card_agg = credit_card.groupby('SK_ID_CURR').agg(['max', 'mean', 'sum', 'var'])\n",
        "    l=[]\n",
        "    for i in credit_card_agg.columns.tolist():\n",
        "      l.append('CR_'+i[0]+'_'+i[1].upper())\n",
        "    credit_card_agg.columns = pd.Index(l)\n",
        "    # Count credit card lines\n",
        "    credit_card_agg['CR_no_COUNT'] = credit_card.groupby('SK_ID_CURR').size()\n",
        "    #print(credit_card_agg.shape)\n",
        "    del credit_card\n",
        "    gc.collect()\n",
        "    return credit_card_agg\n",
        "\n",
        "  def previous_app(prev):\n",
        "    p_app, p_app_cols = one_hot(prev)\n",
        "    p_app['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
        "    p_app['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
        "    p_app['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
        "    p_app['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
        "    p_app['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
        "    p_app['APP_CREDIT_PERC'] = p_app['AMT_APPLICATION'] / p_app['AMT_CREDIT']\n",
        "    num_agg = {'AMT_DOWN_PAYMENT': ['max', 'mean'],'DAYS_DECISION': ['max', 'mean'],\n",
        "                        'AMT_GOODS_PRICE': ['max', 'mean'],'AMT_ANNUITY': ['max', 'mean'],'HOUR_APPR_PROCESS_START': ['max', 'mean'],\n",
        "        'RATE_DOWN_PAYMENT': ['max', 'mean'],'AMT_APPLICATION': ['max', 'mean'],\n",
        "        'AMT_CREDIT': ['max', 'mean'],'APP_CREDIT_PERC': ['max', 'mean'],'CNT_PAYMENT': ['mean', 'sum'] \n",
        "          \n",
        "    }\n",
        "    cat_agg = {}\n",
        "    for cat in p_app_cols:\n",
        "        cat_agg[cat] = ['mean']\n",
        "    \n",
        "    P1 = p_app.groupby('SK_ID_CURR').agg({**num_agg, **cat_agg})\n",
        "    l=[]\n",
        "    for i in P1.columns.tolist():\n",
        "      l.append('PR_'+i[0]+'_'+i[1].upper())\n",
        "    P1.columns = pd.Index(l)\n",
        "    A = p_app[p_app['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
        "    A_agg = A.groupby('SK_ID_CURR').agg(num_agg)\n",
        "    l=[]\n",
        "    for i in A_agg.columns.tolist():\n",
        "      l.append('APP_'+i[0]+'_'+i[1].upper())\n",
        "    A_agg.columns = pd.Index(l)\n",
        "    P1 = P1.join(A_agg, how='left', on='SK_ID_CURR')\n",
        "    R = p_app[p_app['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
        "    R_agg = R.groupby('SK_ID_CURR').agg(num_agg)\n",
        "    l=[]\n",
        "    for i in R_agg.columns.tolist():\n",
        "      l.append('REF_'+i[0]+'_'+i[1].upper())\n",
        "    \n",
        "    R_agg.columns = pd.Index(l)\n",
        "    P1 = P1.join(R_agg, how='left', on='SK_ID_CURR')\n",
        "    del R, R_agg, A, A_agg, p_app\n",
        "    gc.collect()\n",
        "    #print(P1.shape)\n",
        "    return P1\n",
        "\n",
        "  def inst_pay(ins):\n",
        "    A, col = one_hot(ins)\n",
        "    \n",
        "    aggregate = {'days_late_on_payment': ['max','mean','min','sum'],'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
        "        'NUM_INSTALMENT_VERSION': ['nunique'],'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
        "        'amount_extra_paid': ['max','mean','min','sum'],'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']     \n",
        "    }\n",
        "    for c in col:\n",
        "        aggregate[c] = ['mean']\n",
        "    A_agg = A.groupby('SK_ID_CURR').agg(aggregate)\n",
        "    l=[]\n",
        "    for i in A_agg.columns.tolist():\n",
        "      l.append('INS_'+i[0]+'_'+i[1].upper())\n",
        "    A_agg.columns = pd.Index(l)\n",
        "    A_agg['INSTAL_no_COUNT'] = A.groupby('SK_ID_CURR').size()\n",
        "    del A\n",
        "    gc.collect()\n",
        "    #print(A_agg.shape)\n",
        "    return A_agg\n",
        "\n",
        "\n",
        "  b=pd.read_csv('bureau.csv')\n",
        "     \n",
        "  new = b_new(reduce_mem_usage(b))\n",
        "  df = df.join(new, how='left', on='SK_ID_CURR')\n",
        "  del new\n",
        "  gc.collect()\n",
        "\n",
        "    \n",
        "  pr = pd.read_csv('previous_application.csv')\n",
        "\n",
        "  frame = previous_app(reduce_mem_usage(pr))\n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(pr[pr.DAYS_DECISION  >=-365].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = previous_app(frame)\n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_year')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "  \n",
        "  frame = reduce_mem_usage(pr[pr.DAYS_DECISION  >=-182].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = previous_app(frame)      \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_halfyear')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(pr[pr.DAYS_DECISION  >=-92].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = previous_app(frame)      \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_quarter')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(pr[pr.DAYS_DECISION  >=-31].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = previous_app(frame)      \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_month')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(pr[pr.DAYS_DECISION  >=-8].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = previous_app(frame)      \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_week')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  c = reduce_mem_usage(pd.read_csv('POS_CASH_balance.csv'))\n",
        "  frame = pos_cash(c)\n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "        \n",
        "  frame = reduce_mem_usage(c[c.MONTHS_BALANCE >=-12].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = pos_cash(frame)\n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_year')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "  \n",
        "  frame = reduce_mem_usage(c[c.MONTHS_BALANCE >=-6].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = pos_cash(frame)\n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_halfyear')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(c[c.MONTHS_BALANCE >=-3].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = pos_cash(frame)      \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_quarter')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(c[c.MONTHS_BALANCE >=-1].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = pos_cash(frame)      \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_month')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "\n",
        "  #i=pd.read_csv('inst_feats.csv')\n",
        "  i=pd.read_csv('installments_payments.csv')\n",
        "  i['DAYS_ENTRY_PAYMENT'].fillna(100, inplace=True)\n",
        "  i['AMT_PAYMENT'].fillna(0.0, inplace=True)\n",
        "  i['days_late_on_payment']=i.DAYS_ENTRY_PAYMENT-i.DAYS_INSTALMENT\n",
        "  i['amount_extra_paid']=i.AMT_PAYMENT-i.AMT_INSTALMENT\n",
        "  i = reduce_mem_usage(i)\n",
        "  frame = inst_pay(i)\n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(i[i.DAYS_INSTALMENT  >=-365].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = inst_pay(frame)      \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_year')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(i[i.DAYS_INSTALMENT  >=-182].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = inst_pay(frame)       \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_halfyear')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(i[i.DAYS_INSTALMENT  >=-92].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = inst_pay(frame)       \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_quarter')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(i[i.DAYS_INSTALMENT  >=-31].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = inst_pay(frame)       \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_month')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(i[i.DAYS_INSTALMENT  >=-8].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = inst_pay(frame)       \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_week')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  cr=pd.read_csv('credit_card_balance.csv')\n",
        "  frame = credit_card(reduce_mem_usage(cr))\n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(cr[cr.MONTHS_BALANCE >=-12].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = credit_card(frame)     \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_year')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(cr[cr.MONTHS_BALANCE >=-6].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = credit_card(frame)      \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_halfyear')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(cr[cr.MONTHS_BALANCE >=-3].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = credit_card(frame)     \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_quarter')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  frame = reduce_mem_usage(cr[cr.MONTHS_BALANCE >=-1].reset_index())\n",
        "  frame.drop(['index'],axis=1,inplace=True)\n",
        "  frame = credit_card(frame)      \n",
        "  df = df.join(frame, how='left', on='SK_ID_CURR',rsuffix='_month')\n",
        "  del frame\n",
        "  gc.collect()\n",
        "\n",
        "  with open('98_model1.pickle', 'rb') as handle:\n",
        "    m1 = pickle.load(handle)\n",
        "  with open('98_model2.pickle', 'rb') as handle:\n",
        "    m2 = pickle.load(handle)\n",
        "  with open('98_model3.pickle', 'rb') as handle:\n",
        "    m3 = pickle.load(handle)\n",
        "  with open('98_model4.pickle', 'rb') as handle:\n",
        "    m4 = pickle.load(handle)\n",
        "  with open('98_model5.pickle', 'rb') as handle:\n",
        "    m5 = pickle.load(handle)\n",
        "  with open('98_model6.pickle', 'rb') as handle:\n",
        "    m6 = pickle.load(handle)\n",
        "  with open('98_model7.pickle', 'rb') as handle:\n",
        "    m7 = pickle.load(handle)\n",
        "  with open('98_model8.pickle', 'rb') as handle:\n",
        "    m8 = pickle.load(handle)\n",
        "  with open('98_model9.pickle', 'rb') as handle:\n",
        "    m9 = pickle.load(handle)\n",
        "  with open('98_model10.pickle', 'rb') as handle:\n",
        "    m10 = pickle.load(handle)  \n",
        "  \n",
        "  train_df = df[:250000]\n",
        "  y=train_df['TARGET']\n",
        "  #test_df = df[df['TARGET'].isnull()]\n",
        "  #print(\"train shape: {}\".format(train_df.shape))\n",
        "  del df\n",
        "  gc.collect()\n",
        "\n",
        "  feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
        "  out = np.zeros(train_df.shape[0])\n",
        "  out += m1.predict_proba(train_df[feats], num_iteration=m1.best_iteration_)[:,1] / 10\n",
        "  #print('model1 finish')\n",
        "  out += m2.predict_proba(train_df[feats], num_iteration=m2.best_iteration_)[:, 1] / 10\n",
        "  #print('model2 finish')\n",
        "  out += m3.predict_proba(train_df[feats], num_iteration=m3.best_iteration_)[:, 1] / 10\n",
        "  #print('model3 finish')\n",
        "  out += m4.predict_proba(train_df[feats], num_iteration=m4.best_iteration_)[:, 1] / 10\n",
        "  #print('model4 finish')\n",
        "  out += m5.predict_proba(train_df[feats], num_iteration=m5.best_iteration_)[:, 1] / 10\n",
        "  #print('model5 finish')\n",
        "  out += m6.predict_proba(train_df[feats], num_iteration=m6.best_iteration_)[:, 1] / 10\n",
        "  #print('model6 finish')\n",
        "  out += m7.predict_proba(train_df[feats], num_iteration=m7.best_iteration_)[:, 1] / 10\n",
        "  #print('model7 finish')\n",
        "  out += m8.predict_proba(train_df[feats], num_iteration=m8.best_iteration_)[:, 1] / 10\n",
        "  #print('model8 finish')\n",
        "  out += m9.predict_proba(train_df[feats], num_iteration=m9.best_iteration_)[:, 1] / 10\n",
        "  #print('model9 finish')\n",
        "  out += m10.predict_proba(train_df[feats], num_iteration=m10.best_iteration_)[:, 1] / 10\n",
        "  #print('model10 finish')\n",
        "  \n",
        "  return roc_auc_score(y,out)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MTNZ3wx65V4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "ec8dcb6c-8185-4b69-dd2d-ac636030a84c"
      },
      "source": [
        "test_df=pd.read_csv('application_test.csv')\n",
        "test_df=test_df[:1]\n",
        "test=final_fun_1(test_df)\n",
        "test[['SK_ID_CURR', 'TARGET']]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SK_ID_CURR</th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>307511</th>\n",
              "      <td>100001</td>\n",
              "      <td>0.035038</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        SK_ID_CURR    TARGET\n",
              "307511      100001  0.035038"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20CLf-JF8VI4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d3f51b4-e65d-4ac3-e65b-2eb9434585af"
      },
      "source": [
        "train_df=pd.read_csv('application_train.csv')\n",
        "train_df=train_df.reset_index()\n",
        "y=train_df['TARGET']\n",
        "print(final_fun_2(train_df,y))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7836583223570655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcXgrUWeL4VL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}